{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderMap = {0:\"comp.graphics\", 1: \"rec.motorcycle\"}\n",
    "docWordsDictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTokens(foldersPathList):\n",
    "    count=0\n",
    "    docIdsSet = []\n",
    "    for folderCount, path in enumerate(foldersPathList):\n",
    "        for r, d, f in os.walk(path):\n",
    "            for file in f:\n",
    "                filePath = os.path.join(r, file)\n",
    "                fileReference = open(filePath, \"r\", encoding = \"ISO-8859-1\")\n",
    "                fileContent=fileReference.read()\n",
    "                fileContent = fileContent.lower()\n",
    "                tokenizer=RegexpTokenizer(r'([A-Za-z0-9]+)')\n",
    "                tokensList=tokenizer.tokenize(fileContent)\n",
    "                docId = int(file)\n",
    "                docId = docId*100+folderCount\n",
    "                folderMap[folderCount] = r\n",
    "                count+=1\n",
    "                docIdsSet.append(docId)\n",
    "                docWordsDictionary[docId] = tokensList\n",
    "    return docIdsSet, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocumentDetails(doc):\n",
    "        docId = int(doc/100)\n",
    "        docFolder = doc%100\n",
    "        print(folderMap[docFolder], docId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldersPathList = [\n",
    "    '20_newsgroups/comp.graphics',\n",
    "    '20_newsgroups/rec.motorcycles'\n",
    "]\n",
    "docIdsSet, count = getAllTokens(foldersPathList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveInPickle(data, pickleFile):\n",
    "\tfile = open(pickleFile,\"wb\")\n",
    "\tpickle.dump(data,file)\n",
    "\tfile.close()\n",
    "    \n",
    "def loadFromPickle(pickleFile):\n",
    "\tfile = open(pickleFile,'rb')\n",
    "\tpickleData = pickle.load(file)\n",
    "\tfile.close()\n",
    "\treturn pickleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveInPickle(docWordsDictionary, \"q2_docWordsDictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posIndex = {}\n",
    "# print(docIdsSet)\n",
    "# print(docWordsDictionary[3871900])\n",
    "for doc in docWordsDictionary:\n",
    "    wordsList = docWordsDictionary[doc]\n",
    "    for word in wordsList:\n",
    "        if word not in posIndex:\n",
    "            posIndex[word] = {}\n",
    "        indices = [i for i, x in enumerate(wordsList) if x == word]\n",
    "        if(len(indices)>0):\n",
    "            posIndex[word][doc] = indices\n",
    "# print(posIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveInPickle(posIndex, \"q2_posIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start from here \n",
    "posIndex = loadFromPickle(\"q2_posIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the phrase query ...   *Never* expect or believe\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter the phrase query ...   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*Never* expect or believe'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.lower()\n",
    "tokenizer=RegexpTokenizer(r'([A-Za-z0-9]+)')\n",
    "query=tokenizer.tokenize(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "if query[0] not in posIndex:\n",
    "    print(\"query doesnt exist\")\n",
    "else:    \n",
    "    searchDocsList = posIndex[query[0]].keys()\n",
    "    print(len(searchDocsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.motorcycle 72052\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "frequency = 0\n",
    "countDoc = 0\n",
    "for doc in searchDocsList:\n",
    "    w1PosList = posIndex[query[0]][doc]\n",
    "    n = 0\n",
    "    flag = 0\n",
    "    posList = []\n",
    "    for i in range(1, len(query)):\n",
    "        if doc not in posIndex[query[i]]:\n",
    "            flag=1\n",
    "            break\n",
    "        posList = []\n",
    "        w2PosList = posIndex[query[i]][doc]\n",
    "        for pos in w1PosList:\n",
    "            if pos+1 in w2PosList:\n",
    "                posList.append(pos+1)\n",
    "                frequency = len(posList)\n",
    "                n+=1\n",
    "        w1PosList = posList\n",
    "        if(len(posList)== 0):\n",
    "            flag=1\n",
    "            break\n",
    "    if flag == 0:\n",
    "#         print(doc, \" is a match\")\n",
    "        getDocumentDetails(doc)\n",
    "        countDoc+=1\n",
    "#         print(frequency)\n",
    "print(countDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
